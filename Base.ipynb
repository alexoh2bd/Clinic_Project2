{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "def parse_clinical_results(root):\n",
    "    \"\"\"\n",
    "    Parse the clinical results section from XML and return structured data.\n",
    "    \"\"\"\n",
    "    clinical_results = {}\n",
    "    \n",
    "    # Find clinical_results section\n",
    "    results_section = root.find('clinical_results')\n",
    "    if results_section is None:\n",
    "        return clinical_results\n",
    "    \n",
    "    # Parse participant flow\n",
    "    participant_flow = {}\n",
    "    flow_section = results_section.find('participant_flow')\n",
    "    if flow_section is not None:\n",
    "        # Parse groups\n",
    "        groups = []\n",
    "        group_list = flow_section.find('group_list')\n",
    "        if group_list is not None:\n",
    "            for group in group_list.findall('group'):\n",
    "                group_data = {\n",
    "                    'group_id': group.get('group_id', ''),\n",
    "                    'title': group.find('title').text if group.find('title') is not None else '',\n",
    "                    'description': group.find('description').text if group.find('description') is not None else ''\n",
    "                }\n",
    "                groups.append(group_data)\n",
    "        \n",
    "        # Parse periods and milestones\n",
    "        periods = []\n",
    "        period_list = flow_section.find('period_list')\n",
    "        if period_list is not None:\n",
    "            for period in period_list.findall('period'):\n",
    "                period_data = {\n",
    "                    'title': period.find('title').text if period.find('title') is not None else '',\n",
    "                    'milestones': []\n",
    "                }\n",
    "                \n",
    "                milestone_list = period.find('milestone_list')\n",
    "                if milestone_list is not None:\n",
    "                    for milestone in milestone_list.findall('milestone'):\n",
    "                        milestone_data = {\n",
    "                            'title': milestone.find('title').text if milestone.find('title') is not None else '',\n",
    "                            'participants': []\n",
    "                        }\n",
    "                        \n",
    "                        participants_list = milestone.find('participants_list')\n",
    "                        if participants_list is not None:\n",
    "                            for participants in participants_list.findall('participants'):\n",
    "                                participant_data = {\n",
    "                                    'group_id': participants.get('group_id', ''),\n",
    "                                    'count': participants.get('count', '')\n",
    "                                }\n",
    "                                milestone_data['participants'].append(participant_data)\n",
    "                        \n",
    "                        period_data['milestones'].append(milestone_data)\n",
    "                \n",
    "                # Parse drop/withdraw reasons\n",
    "                drop_reasons = []\n",
    "                drop_list = period.find('drop_withdraw_reason_list')\n",
    "                if drop_list is not None:\n",
    "                    for reason in drop_list.findall('drop_withdraw_reason'):\n",
    "                        reason_data = {\n",
    "                            'title': reason.find('title').text if reason.find('title') is not None else '',\n",
    "                            'participants': []\n",
    "                        }\n",
    "                        \n",
    "                        participants_list = reason.find('participants_list')\n",
    "                        if participants_list is not None:\n",
    "                            for participants in participants_list.findall('participants'):\n",
    "                                participant_data = {\n",
    "                                    'group_id': participants.get('group_id', ''),\n",
    "                                    'count': participants.get('count', '')\n",
    "                                }\n",
    "                                reason_data['participants'].append(participant_data)\n",
    "                        \n",
    "                        drop_reasons.append(reason_data)\n",
    "                \n",
    "                period_data['drop_withdraw_reasons'] = drop_reasons\n",
    "                periods.append(period_data)\n",
    "        \n",
    "        participant_flow = {\n",
    "            'groups': groups,\n",
    "            'periods': periods\n",
    "        }\n",
    "    \n",
    "    # Parse baseline characteristics\n",
    "    baseline = {}\n",
    "    baseline_section = results_section.find('baseline')\n",
    "    if baseline_section is not None:\n",
    "        # Parse baseline groups\n",
    "        baseline_groups = []\n",
    "        group_list = baseline_section.find('group_list')\n",
    "        if group_list is not None:\n",
    "            for group in group_list.findall('group'):\n",
    "                group_data = {\n",
    "                    'group_id': group.get('group_id', ''),\n",
    "                    'title': group.find('title').text if group.find('title') is not None else '',\n",
    "                    'description': group.find('description').text if group.find('description') is not None else ''\n",
    "                }\n",
    "                baseline_groups.append(group_data)\n",
    "        \n",
    "        # Parse analyzed participants\n",
    "        analyzed_list = []\n",
    "        analyzed_section = baseline_section.find('analyzed_list')\n",
    "        if analyzed_section is not None:\n",
    "            for analyzed in analyzed_section.findall('analyzed'):\n",
    "                analyzed_data = {\n",
    "                    'units': analyzed.find('units').text if analyzed.find('units') is not None else '',\n",
    "                    'scope': analyzed.find('scope').text if analyzed.find('scope') is not None else '',\n",
    "                    'counts': []\n",
    "                }\n",
    "                \n",
    "                count_list = analyzed.find('count_list')\n",
    "                if count_list is not None:\n",
    "                    for count in count_list.findall('count'):\n",
    "                        count_data = {\n",
    "                            'group_id': count.get('group_id', ''),\n",
    "                            'value': count.get('value', '')\n",
    "                        }\n",
    "                        analyzed_data['counts'].append(count_data)\n",
    "                \n",
    "                analyzed_list.append(analyzed_data)\n",
    "        \n",
    "        # Parse baseline measures\n",
    "        measures = []\n",
    "        measure_list = baseline_section.find('measure_list')\n",
    "        if measure_list is not None:\n",
    "            for measure in measure_list.findall('measure'):\n",
    "                measure_data = {\n",
    "                    'title': measure.find('title').text if measure.find('title') is not None else '',\n",
    "                    'description': measure.find('description').text if measure.find('description') is not None else '',\n",
    "                    'units': measure.find('units').text if measure.find('units') is not None else '',\n",
    "                    'param': measure.find('param').text if measure.find('param') is not None else '',\n",
    "                    'classes': []\n",
    "                }\n",
    "                \n",
    "                class_list = measure.find('class_list')\n",
    "                if class_list is not None:\n",
    "                    for class_elem in class_list.findall('class'):\n",
    "                        class_data = {\n",
    "                            'title': class_elem.find('title').text if class_elem.find('title') is not None else '',\n",
    "                            'categories': []\n",
    "                        }\n",
    "                        \n",
    "                        category_list = class_elem.find('category_list')\n",
    "                        if category_list is not None:\n",
    "                            for category in category_list.findall('category'):\n",
    "                                category_data = {\n",
    "                                    'title': category.find('title').text if category.find('title') is not None else '',\n",
    "                                    'measurements': []\n",
    "                                }\n",
    "                                \n",
    "                                measurement_list = category.find('measurement_list')\n",
    "                                if measurement_list is not None:\n",
    "                                    for measurement in measurement_list.findall('measurement'):\n",
    "                                        measurement_data = {\n",
    "                                            'group_id': measurement.get('group_id', ''),\n",
    "                                            'value': measurement.get('value', ''),\n",
    "                                            'spread': measurement.get('spread', ''),\n",
    "                                            'lower_limit': measurement.get('lower_limit', ''),\n",
    "                                            'upper_limit': measurement.get('upper_limit', '')\n",
    "                                        }\n",
    "                                        category_data['measurements'].append(measurement_data)\n",
    "                                \n",
    "                                class_data['categories'].append(category_data)\n",
    "                        \n",
    "                        measure_data['classes'].append(class_data)\n",
    "                \n",
    "                measures.append(measure_data)\n",
    "        \n",
    "        baseline = {\n",
    "            'groups': baseline_groups,\n",
    "            'analyzed_list': analyzed_list,\n",
    "            'measures': measures\n",
    "        }\n",
    "    \n",
    "    # Parse outcomes\n",
    "    outcomes = []\n",
    "    outcome_list = results_section.find('outcome_list')\n",
    "    if outcome_list is not None:\n",
    "        for outcome in outcome_list.findall('outcome'):\n",
    "            outcome_data = {\n",
    "                'type': outcome.find('type').text if outcome.find('type') is not None else '',\n",
    "                'title': outcome.find('title').text if outcome.find('title') is not None else '',\n",
    "                'description': outcome.find('description').text if outcome.find('description') is not None else '',\n",
    "                'time_frame': outcome.find('time_frame').text if outcome.find('time_frame') is not None else '',\n",
    "                'population': outcome.find('population').text if outcome.find('population') is not None else '',\n",
    "                'groups': [],\n",
    "                'measures': []\n",
    "            }\n",
    "            \n",
    "            # Parse outcome groups\n",
    "            group_list = outcome.find('group_list')\n",
    "            if group_list is not None:\n",
    "                for group in group_list.findall('group'):\n",
    "                    group_data = {\n",
    "                        'group_id': group.get('group_id', ''),\n",
    "                        'title': group.find('title').text if group.find('title') is not None else '',\n",
    "                        'description': group.find('description').text if group.find('description') is not None else ''\n",
    "                    }\n",
    "                    outcome_data['groups'].append(group_data)\n",
    "            \n",
    "            # Parse outcome measures\n",
    "            measure_elem = outcome.find('measure')\n",
    "            if measure_elem is not None:\n",
    "                measure_data = {\n",
    "                    'title': measure_elem.find('title').text if measure_elem.find('title') is not None else '',\n",
    "                    'description': measure_elem.find('description').text if measure_elem.find('description') is not None else '',\n",
    "                    'population': measure_elem.find('population').text if measure_elem.find('population') is not None else '',\n",
    "                    'units': measure_elem.find('units').text if measure_elem.find('units') is not None else '',\n",
    "                    'param': measure_elem.find('param').text if measure_elem.find('param') is not None else '',\n",
    "                    'dispersion': measure_elem.find('dispersion').text if measure_elem.find('dispersion') is not None else '',\n",
    "                    'analyzed_list': [],\n",
    "                    'classes': []\n",
    "                }\n",
    "                \n",
    "                # Parse analyzed participants for this measure\n",
    "                analyzed_list = measure_elem.find('analyzed_list')\n",
    "                if analyzed_list is not None:\n",
    "                    for analyzed in analyzed_list.findall('analyzed'):\n",
    "                        analyzed_data = {\n",
    "                            'units': analyzed.find('units').text if analyzed.find('units') is not None else '',\n",
    "                            'scope': analyzed.find('scope').text if analyzed.find('scope') is not None else '',\n",
    "                            'counts': []\n",
    "                        }\n",
    "                        \n",
    "                        count_list = analyzed.find('count_list')\n",
    "                        if count_list is not None:\n",
    "                            for count in count_list.findall('count'):\n",
    "                                count_data = {\n",
    "                                    'group_id': count.get('group_id', ''),\n",
    "                                    'value': count.get('value', '')\n",
    "                                }\n",
    "                                analyzed_data['counts'].append(count_data)\n",
    "                        \n",
    "                        measure_data['analyzed_list'].append(analyzed_data)\n",
    "                \n",
    "                # Parse measure classes\n",
    "                class_list = measure_elem.find('class_list')\n",
    "                if class_list is not None:\n",
    "                    for class_elem in class_list.findall('class'):\n",
    "                        class_data = {\n",
    "                            'title': class_elem.find('title').text if class_elem.find('title') is not None else '',\n",
    "                            'categories': []\n",
    "                        }\n",
    "                        \n",
    "                        category_list = class_elem.find('category_list')\n",
    "                        if category_list is not None:\n",
    "                            for category in category_list.findall('category'):\n",
    "                                category_data = {\n",
    "                                    'title': category.find('title').text if category.find('title') is not None else '',\n",
    "                                    'measurements': []\n",
    "                                }\n",
    "                                \n",
    "                                measurement_list = category.find('measurement_list')\n",
    "                                if measurement_list is not None:\n",
    "                                    for measurement in measurement_list.findall('measurement'):\n",
    "                                        measurement_data = {\n",
    "                                            'group_id': measurement.get('group_id', ''),\n",
    "                                            'value': measurement.get('value', ''),\n",
    "                                            'spread': measurement.get('spread', ''),\n",
    "                                            'lower_limit': measurement.get('lower_limit', ''),\n",
    "                                            'upper_limit': measurement.get('upper_limit', '')\n",
    "                                        }\n",
    "                                        category_data['measurements'].append(measurement_data)\n",
    "                                \n",
    "                                class_data['categories'].append(category_data)\n",
    "                        \n",
    "                        measure_data['classes'].append(class_data)\n",
    "                \n",
    "                outcome_data['measures'].append(measure_data)\n",
    "            \n",
    "            outcomes.append(outcome_data)\n",
    "    \n",
    "    # Parse reported events (adverse events)\n",
    "    reported_events = {}\n",
    "    events_section = results_section.find('reported_events')\n",
    "    if events_section is not None:\n",
    "        reported_events = {\n",
    "            'time_frame': events_section.find('time_frame').text if events_section.find('time_frame') is not None else '',\n",
    "            'desc': events_section.find('desc').text if events_section.find('desc') is not None else '',\n",
    "            'groups': [],\n",
    "            'serious_events': [],\n",
    "            'other_events': []\n",
    "        }\n",
    "        \n",
    "        # Parse event groups\n",
    "        group_list = events_section.find('group_list')\n",
    "        if group_list is not None:\n",
    "            for group in group_list.findall('group'):\n",
    "                group_data = {\n",
    "                    'group_id': group.get('group_id', ''),\n",
    "                    'title': group.find('title').text if group.find('title') is not None else '',\n",
    "                    'description': group.find('description').text if group.find('description') is not None else ''\n",
    "                }\n",
    "                reported_events['groups'].append(group_data)\n",
    "        \n",
    "        # Parse serious events\n",
    "        serious_events = events_section.find('serious_events')\n",
    "        if serious_events is not None:\n",
    "            serious_data = {\n",
    "                'default_vocab': serious_events.get('default_vocab', ''),\n",
    "                'default_assessment': serious_events.get('default_assessment', ''),\n",
    "                'categories': []\n",
    "            }\n",
    "            \n",
    "            category_list = serious_events.find('category_list')\n",
    "            if category_list is not None:\n",
    "                for category in category_list.findall('category'):\n",
    "                    category_data = {\n",
    "                        'title': category.find('title').text if category.find('title') is not None else '',\n",
    "                        'events': []\n",
    "                    }\n",
    "                    \n",
    "                    event_list = category.find('event_list')\n",
    "                    if event_list is not None:\n",
    "                        for event in event_list.findall('event'):\n",
    "                            event_data = {\n",
    "                                'sub_title': event.find('sub_title').text if event.find('sub_title') is not None else '',\n",
    "                                'assessment': event.get('assessment', ''),\n",
    "                                'counts': []\n",
    "                            }\n",
    "                            \n",
    "                            counts_elem = event.find('counts')\n",
    "                            if counts_elem is not None:\n",
    "                                for count_attr in ['subjects_affected', 'subjects_at_risk', 'events']:\n",
    "                                    if counts_elem.get(count_attr):\n",
    "                                        count_data = {\n",
    "                                            'group_id': counts_elem.get('group_id', ''),\n",
    "                                            'type': count_attr,\n",
    "                                            'value': counts_elem.get(count_attr, '')\n",
    "                                        }\n",
    "                                        event_data['counts'].append(count_data)\n",
    "                            \n",
    "                            category_data['events'].append(event_data)\n",
    "                    \n",
    "                    serious_data['categories'].append(category_data)\n",
    "            \n",
    "            reported_events['serious_events'] = serious_data\n",
    "        \n",
    "        # Parse other events (similar structure to serious events)\n",
    "        other_events = events_section.find('other_events')\n",
    "        if other_events is not None:\n",
    "            other_data = {\n",
    "                'frequency_threshold': other_events.get('frequency_threshold', ''),\n",
    "                'default_vocab': other_events.get('default_vocab', ''),\n",
    "                'default_assessment': other_events.get('default_assessment', ''),\n",
    "                'categories': []\n",
    "            }\n",
    "            \n",
    "            category_list = other_events.find('category_list')\n",
    "            if category_list is not None:\n",
    "                for category in category_list.findall('category'):\n",
    "                    category_data = {\n",
    "                        'title': category.find('title').text if category.find('title') is not None else '',\n",
    "                        'events': []\n",
    "                    }\n",
    "                    \n",
    "                    event_list = category.find('event_list')\n",
    "                    if event_list is not None:\n",
    "                        for event in event_list.findall('event'):\n",
    "                            event_data = {\n",
    "                                'sub_title': event.find('sub_title').text if event.find('sub_title') is not None else '',\n",
    "                                'assessment': event.get('assessment', ''),\n",
    "                                'counts': []\n",
    "                            }\n",
    "                            \n",
    "                            counts_elem = event.find('counts')\n",
    "                            if counts_elem is not None:\n",
    "                                for count_attr in ['subjects_affected', 'subjects_at_risk', 'events']:\n",
    "                                    if counts_elem.get(count_attr):\n",
    "                                        count_data = {\n",
    "                                            'group_id': counts_elem.get('group_id', ''),\n",
    "                                            'type': count_attr,\n",
    "                                            'value': counts_elem.get(count_attr, '')\n",
    "                                        }\n",
    "                                        event_data['counts'].append(count_data)\n",
    "                            \n",
    "                            category_data['events'].append(event_data)\n",
    "                    \n",
    "                    other_data['categories'].append(category_data)\n",
    "            \n",
    "            reported_events['other_events'] = other_data\n",
    "    \n",
    "    # Parse agreements and point of contact\n",
    "    agreements = {}\n",
    "    agreements_section = results_section.find('certain_agreements')\n",
    "    if agreements_section is not None:\n",
    "        agreements = {\n",
    "            'pi_employee': agreements_section.find('pi_employee').text if agreements_section.find('pi_employee') is not None else '',\n",
    "            'restrictive_agreement': agreements_section.find('restrictive_agreement').text if agreements_section.find('restrictive_agreement') is not None else ''\n",
    "        }\n",
    "    \n",
    "    point_of_contact = {}\n",
    "    contact_section = results_section.find('point_of_contact')\n",
    "    if contact_section is not None:\n",
    "        point_of_contact = {\n",
    "            'name_or_title': contact_section.find('name_or_title').text if contact_section.find('name_or_title') is not None else '',\n",
    "            'organization': contact_section.find('organization').text if contact_section.find('organization') is not None else '',\n",
    "            'phone': contact_section.find('phone').text if contact_section.find('phone') is not None else '',\n",
    "            'email': contact_section.find('email').text if contact_section.find('email') is not None else ''\n",
    "        }\n",
    "    \n",
    "    # Assemble clinical results\n",
    "    clinical_results = {\n",
    "        'participant_flow': participant_flow,\n",
    "        'baseline': baseline,\n",
    "        'outcomes': outcomes,\n",
    "        'reported_events': reported_events,\n",
    "        'certain_agreements': agreements,\n",
    "        'point_of_contact': point_of_contact\n",
    "    }\n",
    "    \n",
    "    return clinical_results\n",
    "\n",
    "\n",
    "def xmlfile2results(xml_file):\n",
    "    \"\"\"\n",
    "    Parse clinical trial XML file and return a dictionary with extracted data.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Basic study identifiers\n",
    "    nctid = root.find('id_info/nct_id').text if root.find('id_info/nct_id') is not None else ''\n",
    "    org_study_id = root.find('id_info/org_study_id').text if root.find('id_info/org_study_id') is not None else ''\n",
    "    url = root.find('required_header/url').text if root.find('required_header/url') is not None else ''\n",
    "    \n",
    "    # Titles - handle both brief_title and official_title\n",
    "    brief_title = root.find('brief_title').text if root.find('brief_title') is not None else ''\n",
    "    official_title = root.find('official_title').text if root.find('official_title') is not None else ''\n",
    "    \n",
    "    # Sponsors and collaborators\n",
    "    lead_sponsor = ''\n",
    "    collaborators = []\n",
    "    sponsors = root.find('sponsors')\n",
    "    if sponsors is not None:\n",
    "        lead_sponsor_elem = sponsors.find('lead_sponsor/agency')\n",
    "        if lead_sponsor_elem is not None:\n",
    "            lead_sponsor = lead_sponsor_elem.text\n",
    "        \n",
    "        for collab in sponsors.findall('collaborator/agency'):\n",
    "            if collab is not None:\n",
    "                collaborators.append(collab.text)\n",
    "    \n",
    "    # Study descriptions\n",
    "    brief_summary = ''\n",
    "    brief_summary_elem = root.find('brief_summary/textblock')\n",
    "    if brief_summary_elem is not None:\n",
    "        brief_summary = brief_summary_elem.text.strip() if brief_summary_elem.text else ''\n",
    "    \n",
    "    detailed_description = ''\n",
    "    detailed_description_elem = root.find('detailed_description/textblock')\n",
    "    if detailed_description_elem is not None:\n",
    "        detailed_description = detailed_description_elem.text.strip() if detailed_description_elem.text else ''\n",
    "    \n",
    "    # Study type and phase\n",
    "    study_type = root.find('study_type').text if root.find('study_type') is not None else ''\n",
    "    phase = root.find('phase').text if root.find('phase') is not None else ''\n",
    "    \n",
    "    # Status and dates\n",
    "    overall_status = root.find('overall_status').text if root.find('overall_status') is not None else ''\n",
    "    why_stopped = root.find('why_stopped').text if root.find('why_stopped') is not None else ''\n",
    "\n",
    "    # create an inferred label from the overall_status and why_stopped\n",
    "    \n",
    "    \n",
    "    # Handle dates with potential type attributes\n",
    "    start_date = ''\n",
    "    start_date_type = ''\n",
    "    start_date_elem = root.find('start_date')\n",
    "    if start_date_elem is not None:\n",
    "        start_date = start_date_elem.text if start_date_elem.text else ''\n",
    "        start_date_type = start_date_elem.get('type', '')\n",
    "    \n",
    "    completion_date = ''\n",
    "    completion_date_type = ''\n",
    "    # Check both completion_date and primary_completion_date\n",
    "    completion_date_elem = root.find('completion_date')\n",
    "    if completion_date_elem is None:\n",
    "        completion_date_elem = root.find('primary_completion_date')\n",
    "    if completion_date_elem is not None:\n",
    "        completion_date = completion_date_elem.text if completion_date_elem.text else ''\n",
    "        completion_date_type = completion_date_elem.get('type', '')\n",
    "    \n",
    "    study_first_posted = ''\n",
    "    study_first_posted_elem = root.find('study_first_posted')\n",
    "    if study_first_posted_elem is not None:\n",
    "        study_first_posted = study_first_posted_elem.text if study_first_posted_elem.text else ''\n",
    "    \n",
    "    # Interventions - handle all types, not just drugs\n",
    "    interventions = []\n",
    "    for intervention in root.findall('intervention'):\n",
    "        intervention_data = {}\n",
    "        intervention_type_elem = intervention.find('intervention_type')\n",
    "        intervention_name_elem = intervention.find('intervention_name')\n",
    "        intervention_desc_elem = intervention.find('description')\n",
    "        \n",
    "        if intervention_type_elem is not None:\n",
    "            intervention_data['type'] = intervention_type_elem.text\n",
    "        if intervention_name_elem is not None:\n",
    "            intervention_data['name'] = intervention_name_elem.text\n",
    "        if intervention_desc_elem is not None:\n",
    "            intervention_data['description'] = intervention_desc_elem.text\n",
    "\n",
    "    # add intervention Mesh terms\n",
    "    # Get only intervention mesh terms\n",
    "    intervention_section = root.find('intervention_browse')\n",
    "    if intervention_section is not None:\n",
    "        intervention_mesh_terms = [term.text.strip() for term in intervention_section.findall('mesh_term')]\n",
    "    else:\n",
    "        intervention_mesh_terms = []\n",
    "    \n",
    "    # Extract drug interventions separately for backward compatibility\n",
    "    drug_interventions = [i['name'] for i in interventions if i.get('type') == 'Drug' and 'name' in i]\n",
    "    \n",
    "    # Arm groups\n",
    "    arm_groups = []\n",
    "    for ag in root.findall('arm_group'):\n",
    "        arm_data = {}\n",
    "        label_elem = ag.find('arm_group_label')\n",
    "        desc_elem = ag.find('description')\n",
    "        type_elem = ag.find('arm_group_type')\n",
    "        \n",
    "        if label_elem is not None:\n",
    "            arm_data['label'] = label_elem.text\n",
    "        if desc_elem is not None:\n",
    "            arm_data['description'] = desc_elem.text\n",
    "        if type_elem is not None:\n",
    "            arm_data['type'] = type_elem.text\n",
    "        \n",
    "        if arm_data:\n",
    "            arm_groups.append(arm_data)\n",
    "    \n",
    "    # Study design information\n",
    "    study_design_info = {}\n",
    "    sdi = root.find('study_design_info')\n",
    "    if sdi is not None:\n",
    "        for child in sdi:\n",
    "            if child.text:\n",
    "                study_design_info[child.tag] = child.text\n",
    "\n",
    "    # Clinical Results\n",
    "    \n",
    "    # Primary outcome\n",
    "    primary_outcomes = []\n",
    "    for po in root.findall('primary_outcome'):\n",
    "        outcome_data = {}\n",
    "        measure_elem = po.find('measure')\n",
    "        time_frame_elem = po.find('time_frame')\n",
    "        description_elem = po.find('description')\n",
    "        \n",
    "        if measure_elem is not None:\n",
    "            outcome_data['measure'] = measure_elem.text\n",
    "        if time_frame_elem is not None:\n",
    "            outcome_data['time_frame'] = time_frame_elem.text\n",
    "        if description_elem is not None:\n",
    "            outcome_data['description'] = description_elem.text\n",
    "        \n",
    "        if outcome_data:\n",
    "            primary_outcomes.append(outcome_data)\n",
    "    \n",
    "    # Secondary outcomes\n",
    "    secondary_outcomes = []\n",
    "    for so in root.findall('secondary_outcome'):\n",
    "        outcome_data = {}\n",
    "        measure_elem = so.find('measure')\n",
    "        time_frame_elem = so.find('time_frame')\n",
    "        description_elem = so.find('description')\n",
    "        \n",
    "        if measure_elem is not None:\n",
    "            outcome_data['measure'] = measure_elem.text\n",
    "        if time_frame_elem is not None:\n",
    "            outcome_data['time_frame'] = time_frame_elem.text\n",
    "        if description_elem is not None:\n",
    "            outcome_data['description'] = description_elem.text\n",
    "        \n",
    "        if outcome_data:\n",
    "            secondary_outcomes.append(outcome_data)\n",
    "    \n",
    "    # Conditions/indications\n",
    "    conditions = [condition.text.strip() for condition in root.findall('condition')]\n",
    "    \n",
    "    # MeSH terms for conditions\n",
    "    conditions_mesh_terms = []\n",
    "    conditions_section = root.find('condition_browse')\n",
    "    if conditions_section is not None:\n",
    "        conditions_mesh_terms = [term.text.strip() for term in conditions_section.findall('mesh_term')]\n",
    "    \n",
    "    # Enrollment\n",
    "    enrollment = ''\n",
    "    enrollment_type = ''\n",
    "    enrollment_elem = root.find('enrollment')\n",
    "    if enrollment_elem is not None:\n",
    "        enrollment = enrollment_elem.text if enrollment_elem.text else ''\n",
    "        enrollment_type = enrollment_elem.get('type', '')\n",
    "    \n",
    "    # Eligibility criteria\n",
    "    criteria = ''\n",
    "    criteria_elem = root.find('eligibility/criteria/textblock')\n",
    "    if criteria_elem is not None:\n",
    "        criteria = criteria_elem.text.strip() if criteria_elem.text else ''\n",
    "    \n",
    "    # Gender, age constraints\n",
    "    gender = ''\n",
    "    minimum_age = ''\n",
    "    maximum_age = ''\n",
    "    healthy_volunteers = ''\n",
    "    \n",
    "    eligibility = root.find('eligibility')\n",
    "    if eligibility is not None:\n",
    "        gender_elem = eligibility.find('gender')\n",
    "        min_age_elem = eligibility.find('minimum_age')\n",
    "        max_age_elem = eligibility.find('maximum_age')\n",
    "        healthy_elem = eligibility.find('healthy_volunteers')\n",
    "        \n",
    "        if gender_elem is not None:\n",
    "            gender = gender_elem.text\n",
    "        if min_age_elem is not None:\n",
    "            minimum_age = min_age_elem.text\n",
    "        if max_age_elem is not None:\n",
    "            maximum_age = max_age_elem.text\n",
    "        if healthy_elem is not None:\n",
    "            healthy_volunteers = healthy_elem.text\n",
    "    \n",
    "    # Number of groups\n",
    "    number_of_groups = root.find('number_of_groups').text if root.find('number_of_groups') is not None else ''\n",
    "    \n",
    "    # Locations\n",
    "    locations = []\n",
    "    for loc in root.findall('location'):\n",
    "        location_data = {}\n",
    "        facility = loc.find('facility')\n",
    "        if facility is not None:\n",
    "            name_elem = facility.find('name')\n",
    "            if name_elem is not None:\n",
    "                location_data['facility_name'] = name_elem.text\n",
    "            \n",
    "            address = facility.find('address')\n",
    "            if address is not None:\n",
    "                city_elem = address.find('city')\n",
    "                state_elem = address.find('state')\n",
    "                zip_elem = address.find('zip')\n",
    "                country_elem = address.find('country')\n",
    "                \n",
    "                if city_elem is not None:\n",
    "                    location_data['city'] = city_elem.text\n",
    "                if state_elem is not None:\n",
    "                    location_data['state'] = state_elem.text\n",
    "                if zip_elem is not None:\n",
    "                    location_data['zip'] = zip_elem.text\n",
    "                if country_elem is not None:\n",
    "                    location_data['country'] = country_elem.text\n",
    "        \n",
    "        # Location status\n",
    "        status_elem = loc.find('status')\n",
    "        if status_elem is not None:\n",
    "            location_data['status'] = status_elem.text\n",
    "        \n",
    "        # Contact information\n",
    "        contact = loc.find('contact')\n",
    "        if contact is not None:\n",
    "            contact_name = contact.find('last_name')\n",
    "            contact_email = contact.find('email')\n",
    "            contact_phone = contact.find('phone')\n",
    "            \n",
    "            if contact_name is not None:\n",
    "                location_data['contact_name'] = contact_name.text\n",
    "            if contact_email is not None:\n",
    "                location_data['contact_email'] = contact_email.text\n",
    "            if contact_phone is not None:\n",
    "                location_data['contact_phone'] = contact_phone.text\n",
    "        \n",
    "        if location_data:\n",
    "            locations.append(location_data)\n",
    "    \n",
    "    # Overall contacts\n",
    "    overall_contact = {}\n",
    "    contact = root.find('overall_contact')\n",
    "    if contact is not None:\n",
    "        name_elem = contact.find('last_name')\n",
    "        email_elem = contact.find('email')\n",
    "        phone_elem = contact.find('phone')\n",
    "        \n",
    "        if name_elem is not None:\n",
    "            overall_contact['name'] = name_elem.text\n",
    "        if email_elem is not None:\n",
    "            overall_contact['email'] = email_elem.text\n",
    "        if phone_elem is not None:\n",
    "            overall_contact['phone'] = phone_elem.text\n",
    "    \n",
    "    # Oversight info\n",
    "    oversight_info = {}\n",
    "    oversight = root.find('oversight_info')\n",
    "    if oversight is not None:\n",
    "        for child in oversight:\n",
    "            if child.text:\n",
    "                oversight_info[child.tag] = child.text\n",
    "    \n",
    "    # Keywords\n",
    "    keywords = []\n",
    "    for keyword in root.findall('keyword'):\n",
    "        if keyword.text:\n",
    "            keywords.append(keyword.text)\n",
    "\n",
    "    # Clinical Results\n",
    "    clinical_results = parse_clinical_results(root)\n",
    "    \n",
    "    # Assemble the complete data dictionary\n",
    "    data = {\n",
    "        'nctid': nctid,\n",
    "        'org_study_id': org_study_id,\n",
    "        'url': url,\n",
    "        'brief_title': brief_title,\n",
    "        'official_title': official_title,\n",
    "        'lead_sponsor': lead_sponsor,\n",
    "        'collaborators': collaborators,\n",
    "        'brief_summary': brief_summary,\n",
    "        'detailed_description': detailed_description,\n",
    "        'study_type': study_type,\n",
    "        'phase': phase,\n",
    "        'overall_status': overall_status,\n",
    "        'why_stopped': why_stopped,\n",
    "        'start_date': start_date,\n",
    "        'start_date_type': start_date_type,\n",
    "        'completion_date': completion_date,\n",
    "        'completion_date_type': completion_date_type,\n",
    "        'study_first_posted': study_first_posted,\n",
    "        'interventions': interventions,\n",
    "        'intervention_mesh_terms': intervention_mesh_terms,\n",
    "        'drug_interventions': drug_interventions,  # for backward compatibility\n",
    "        'arm_groups': arm_groups,\n",
    "        'study_design_info': study_design_info,\n",
    "        'primary_outcomes': primary_outcomes,\n",
    "        'secondary_outcomes': secondary_outcomes,\n",
    "        'conditions': conditions,\n",
    "        'conditions_mesh_terms': conditions_mesh_terms,\n",
    "        'enrollment': enrollment,\n",
    "        'enrollment_type': enrollment_type,\n",
    "        'criteria': criteria,\n",
    "        'gender': gender,\n",
    "        'minimum_age': minimum_age,\n",
    "        'maximum_age': maximum_age,\n",
    "        'healthy_volunteers': healthy_volunteers,\n",
    "        'number_of_groups': number_of_groups,\n",
    "        'locations': locations,\n",
    "        'overall_contact': overall_contact,\n",
    "        'oversight_info': oversight_info,\n",
    "        'keywords': keywords,\n",
    "        'clinical_results': clinical_results\n",
    "    }\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "chunk_size = 100\n",
    "feat_cats = ['brief_summary', 'detailed_description']\n",
    "pdir = \"data_processed/\"\n",
    "os.makedirs(pdir, exist_ok=True)\n",
    "\n",
    "# Lists for final labels\n",
    "overall_statuses = []\n",
    "clinical_results = []\n",
    "phases = []\n",
    "\n",
    "# Temporary list for text features\n",
    "X = []\n",
    "\n",
    "# Loop through all folders\n",
    "folders = os.listdir('raw_data/')\n",
    "for idx, folder in enumerate(folders):\n",
    "    base = os.path.join('raw_data', folder)\n",
    "    if not os.path.isdir(base):\n",
    "        continue\n",
    "    \n",
    "    for file in os.listdir(base):\n",
    "        xml_path = os.path.join(base, file)\n",
    "        try:\n",
    "            data = xmlfile2results(xml_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {xml_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Skip entries with missing phase\n",
    "        phase = data.get('phase', '').strip()\n",
    "        if not phase or phase.upper() == 'N/A':\n",
    "            continue\n",
    "        \n",
    "        # Collect text features safely\n",
    "        textfeats = \"\"\n",
    "        for feat in feat_cats:\n",
    "            textfeats += data.get(feat, '')\n",
    "        textfeats += \"\".join(data.get('interventions', []))\n",
    "        for po in data.get('primary_outcomes', []):\n",
    "            textfeats += po.get('measure', '')\n",
    "            textfeats += \"\".join(po.get('description', []))\n",
    "        \n",
    "        X.append(textfeats)\n",
    "        overall_statuses.append(data.get('overall_status'))\n",
    "        clinical_results.append(data.get('clinical_results'))\n",
    "        phases.append(phase)\n",
    "    \n",
    "\n",
    "# Create binary target y\n",
    "y = np.array([\n",
    "    1 if (str(overall_statuses[i]).lower() == 'completed' \n",
    "          and clinical_results[i] is not None\n",
    "          and phases[i].lower() in ['phase 2/phase 3','phase 3','phase 4'])\n",
    "    else 0\n",
    "    for i in range(len(overall_statuses))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=random_seed, shuffle=True, test_size=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998120742306789 0.6046948356807512 0.39188640973630834 0.47556923076923074\n",
      "[0 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TF-IDF: Total Frequency - Inverse Document Frequency\n",
    "    Extracts Important words in documents, higher scores: greater relevance\n",
    "\n",
    "Official Title\n",
    "Brief Summary\n",
    "https://www.geeksforgeeks.org/machine-learning/understanding-tf-idf-term-frequency-inverse-document-frequency/\n",
    "\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "result=tfidf.fit_transform(X_train)\n",
    "# print('result: ', result)\n",
    "# print('\\nidf values:')\n",
    "# for ele1, ele2 in zip(tfidf.get_feature_names_out(), tfidf.idf_):\n",
    "#     print(ele1, ':', ele2)\n",
    "\n",
    "tfidf_means = np.asarray(result.mean(axis=0)).ravel()\n",
    "\n",
    "K = 5000    # choose your number of features\n",
    "top_idx = np.argsort(tfidf_means)[-K:]   # indices of top K tf-idf features\n",
    "selected_terms = [tfidf.get_feature_names_out()[i] for i in top_idx]\n",
    "vectorizer_reduced = TfidfVectorizer(vocabulary=selected_terms)\n",
    "X_train_reduced = vectorizer_reduced.fit_transform(X_train)\n",
    "# X_reduced\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train_reduced, y_train)\n",
    "X_test_reduced = vectorizer_reduced.transform(X_test)\n",
    "y_preds = model.predict(X_test_reduced)\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test,y_preds), precision_score(y_test,y_preds), recall_score(y_test,y_preds), f1_score(y_test,y_preds))\n",
    "print(y_preds)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8062955132722575 0.6114333057166529 0.44908722109533467 0.5178341714419367\n",
      "[0 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=None)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "coefs = clf.coef_.ravel()          # shape: (n_features,)\n",
    "abs_coefs = np.abs(coefs)\n",
    "top_idx = np.argsort(abs_coefs)[-K:]\n",
    "selected_terms = vectorizer.get_feature_names_out()[top_idx]\n",
    "\n",
    "vectorizer_reduced = TfidfVectorizer(vocabulary=selected_terms)\n",
    "X_train_reduced = vectorizer_reduced.fit_transform(X_train)\n",
    "clf_final = LogisticRegression(max_iter=5000)\n",
    "clf_final.fit(X_train_reduced, y_train)\n",
    "X_test_reduced = vectorizer_reduced.fit_transform(X_test)\n",
    "\n",
    "preds = clf_final.predict(X_test_reduced)\n",
    "print(accuracy_score(y_test,preds), precision_score(y_test,preds), recall_score(y_test,preds), f1_score(y_test,preds))\n",
    "print(preds)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8062955132722575 \n",
    "Precision: 0.6114333057166529 \n",
    "Recall: 0.44908722109533467 \n",
    "F1: 0.5178341714419367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "\n",
    "random_state=42\n",
    "\n",
    "# tfidf\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000,\n",
    "    min_df=3,\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "svd = TruncatedSVD(n_components=400, random_state=random_state)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 44364, number of negative: 147196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 102000\n",
      "[LightGBM] [Info] Number of data points in the train set: 191560, number of used features: 400\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.231593 -> initscore=-1.199337\n",
      "[LightGBM] [Info] Start training from score -1.199337\n",
      "Accuracy: 0.8005167958656331\n",
      "AUC: 0.8292938931652738\n",
      "Precision: 0.6555959963603276\n",
      "Recall: 0.2922920892494929\n",
      "F1: 0.404320987654321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexoh/Downloads/Clinic_Project2/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(X_train_svd, y_train)\n",
    "\n",
    "pred_prob = model.predict_proba(X_test_svd)[:,1]\n",
    "pred_label = (pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_label))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_prob))\n",
    "print(\"Precision:\", precision_score(y_test, pred_label))\n",
    "print(\"Recall:\", recall_score(y_test, pred_label))\n",
    "print(\"F1:\", f1_score(y_test, pred_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8005167958656331\n",
    "AUC: 0.8292938931652738\n",
    "Precision: 0.6555959963603276\n",
    "Recall: 0.2922920892494929\n",
    "F1: 0.404320987654321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 44364, number of negative: 147196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 30.479729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6216485\n",
      "[LightGBM] [Info] Number of data points in the train set: 191560, number of used features: 49976\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.231593 -> initscore=-1.199337\n",
      "[LightGBM] [Info] Start training from score -1.199337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexoh/Downloads/Clinic_Project2/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8042283298097251\n",
      "AUC: 0.8476170514379547\n",
      "Precision: 0.6414534668149796\n",
      "Recall: 0.3509127789046653\n",
      "F1: 0.4536515012455749\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "pred_prob = model.predict_proba(X_test_tfidf)[:,1]\n",
    "pred_label = (pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_label))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_prob))\n",
    "print(\"Precision:\", precision_score(y_test, pred_label))\n",
    "print(\"Recall:\", recall_score(y_test, pred_label))\n",
    "print(\"F1:\", f1_score(y_test, pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8042283298097251\n",
    "AUC: 0.8476170514379547\n",
    "Precision: 0.6414534668149796\n",
    "Recall: 0.3509127789046653\n",
    "F1: 0.4536515012455749"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
